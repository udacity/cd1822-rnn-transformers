{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-12T16:41:11.761289Z",
     "end_time": "2023-04-12T16:41:14.515067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.4094054698944092\n",
      "Epoch: 200, Loss: 0.03397029638290405\n",
      "Epoch: 300, Loss: 0.012075490318238735\n",
      "Epoch: 400, Loss: 0.006638178136199713\n",
      "Epoch: 500, Loss: 0.0043108901008963585\n",
      "Epoch: 600, Loss: 0.0030620284378528595\n",
      "Epoch: 700, Loss: 0.0023015905171632767\n",
      "Epoch: 800, Loss: 0.0017992026405408978\n",
      "Epoch: 900, Loss: 0.0014477409422397614\n",
      "Epoch: 1000, Loss: 0.0011911113979294896\n",
      "Test predictions: tensor([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Phrases (textual data) and their category labels (0 for sports, 1 for technology, 2 for food)\n",
    "# note: this model might overfit as the data is less. feel free to use any other data source for training\n",
    "# or create your own dummy data\n",
    "phrases = [\"great goal scored\", \"amazing touchdown\", \"new phone release\", \"latest laptop model\", \"tasty pizza\", \"delicious burger\"]\n",
    "categories = [0, 0, 1, 1, 2, 2]\n",
    "\n",
    "# Create a vocabulary to represent words as indices\n",
    "vocab = {\"<PAD>\": 0, \"great\": 1, \"goal\": 2, \"scored\": 3, \"amazing\": 4, \"touchdown\": 5, \"new\": 6, \"phone\": 7, \"release\": 8, \"latest\": 9, \"laptop\": 10, \"model\": 11, \"tasty\": 12, \"pizza\": 13, \"delicious\": 14, \"burger\": 15}\n",
    "\n",
    "# Tokenize, encode, and pad phrases\n",
    "encoded_phrases = [[vocab[word] for word in phrase.split()] for phrase in phrases]\n",
    "max_length = max([len(phrase) for phrase in encoded_phrases])\n",
    "padded_phrases = [phrase + [vocab[\"<PAD>\"]] * (max_length - len(phrase)) for phrase in encoded_phrases]\n",
    "\n",
    "# Convert phrases and categories to PyTorch tensors\n",
    "inputs = torch.LongTensor(padded_phrases)\n",
    "labels = torch.LongTensor(categories)\n",
    "\n",
    "# Define LSTM model\n",
    "class PhraseClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(PhraseClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, (hidden, _) = self.lstm(embedded)\n",
    "        logits = self.fc(hidden.squeeze(0))\n",
    "        return logits\n",
    "\n",
    "# Instantiate model and define loss and optimizer\n",
    "model = PhraseClassifier(len(vocab), embedding_dim=10, hidden_dim=20, output_dim=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model for a number of epochs\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(inputs.t())\n",
    "    loss = criterion(predictions, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch: {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "# Test the model on new phrases\n",
    "with torch.no_grad():\n",
    "    test_phrases = [\"incredible match\", \"newest gadget\", \"yummy cake\"]\n",
    "    encoded_test_phrases = [[vocab.get(word, vocab[\"<PAD>\"]) for word in phrase.split()] for phrase in test_phrases]\n",
    "    padded_test_phrases = [phrase + [vocab[\"<PAD>\"]] * (max_length - len(phrase)) for phrase in encoded_test_phrases]\n",
    "    test_inputs = torch.LongTensor(padded_test_phrases)\n",
    "    test_predictions = torch.argmax(model(test_inputs.t()), dim=1)\n",
    "    print(\"Test predictions:\", test_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results clearly indicate an overfitted model. We can improve the testing accuracy by getting more data. That would be an Optional TODO for you."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
